{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759a835-3c01-4bf2-b1d7-b2124648b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamap import experiment_files\n",
    "experiment_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c1cdae-c878-4a3c-a503-ae6301d625ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a83e68d9-520f-47f0-8c9c-0271b3faa632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(activation='mish', amp=False, arch='[[-1, 256, 0, 3, 1, 1, 0], [-1, 256, 1, 10, 1, 1, 1], [-1, 256, 1, 10, 10, 1, 1], [-1, 320, 1, 10, 1, 1, 1], [-1, 384, 1, 15, 1, 1, 1], [-1, 448, 1, 20, 1, 1, 1], [-1, 512, 1, 25, 1, 1, 1], [-1, 512, 1, 30, 1, 1, 1], [-1, 512, 1, 35, 1, 1, 1], [-1, 512, 1, 40, 1, 1, 1], [-1, 512, 1, 45, 1, 1, 1], [-1, 512, 1, 50, 1, 1, 1], [-1, 768, 1, 55, 1, 1, 1], [-1, 768, 1, 60, 1, 1, 1], [-1, 768, 1, 65, 1, 1, 1], [-1, 768, 1, 70, 1, 1, 1], [-1, 768, 1, 75, 1, 1, 1], [-1, 768, 1, 80, 1, 1, 1], [-1, 768, 1, 85, 1, 1, 1], [-1, 768, 1, 90, 1, 1, 1], [-1, 768, 1, 95, 1, 1, 1], [-1, 768, 1, 100, 1, 1, 1]]\\n', batchsize=30, dropout=0.1, epochs=30, gradclip=0, half=False, lr=0.002, name='1210', optimizer='ranger', orig={'name': '1210', 'seqlen': 4096, 'epochs': 30, 'optimizer': 'ranger', 'lr': 0.002, 'weightdecay': 0.01, 'batchsize': 30, 'dropout': 0.1, 'activation': 'mish', 'sqex_activation': 'mish', 'sqex_reduction': 32, 'trainfile': '/s/neptune/a/tmp/newrna2-train-4096-1M.hdf5', 'validfile': '/s/neptune/a/tmp/newrna2-valid-4096-1M.hdf5', 'amp': False, 'half': False, 'scheduler': 'reducelronplateau', 'scheduler_patience': 1, 'scheduler_factor': 0.5, 'scheduler_threshold': 0.1, 'scheduler_minlr': 1e-05, 'scheduler_reduce': 2, 'gradclip': 0, 'train_loopcount': 1000000, 'valid_loopcount': 1000, 'tensorboard': False, 'vocab': ['<PAD>', 'A', 'C', 'G', 'T'], 'saveinit': False, 'arch': '[[-1, 256, 0, 3, 1, 1, 0], [-1, 256, 1, 10, 1, 1, 1], [-1, 256, 1, 10, 10, 1, 1], [-1, 320, 1, 10, 1, 1, 1], [-1, 384, 1, 15, 1, 1, 1], [-1, 448, 1, 20, 1, 1, 1], [-1, 512, 1, 25, 1, 1, 1], [-1, 512, 1, 30, 1, 1, 1], [-1, 512, 1, 35, 1, 1, 1], [-1, 512, 1, 40, 1, 1, 1], [-1, 512, 1, 45, 1, 1, 1], [-1, 512, 1, 50, 1, 1, 1], [-1, 768, 1, 55, 1, 1, 1], [-1, 768, 1, 60, 1, 1, 1], [-1, 768, 1, 65, 1, 1, 1], [-1, 768, 1, 70, 1, 1, 1], [-1, 768, 1, 75, 1, 1, 1], [-1, 768, 1, 80, 1, 1, 1], [-1, 768, 1, 85, 1, 1, 1], [-1, 768, 1, 90, 1, 1, 1], [-1, 768, 1, 95, 1, 1, 1], [-1, 768, 1, 100, 1, 1, 1]]\\n', 'orig': {...}}, saveinit=False, scheduler='reducelronplateau', scheduler_factor=0.5, scheduler_minlr=1e-05, scheduler_patience=1, scheduler_reduce=2, scheduler_threshold=0.1, seqlen=4096, sqex_activation='mish', sqex_reduction=32, tensorboard=False, train_loopcount=1000000, trainfile='/s/neptune/a/tmp/newrna2-train-4096-1M.hdf5', valid_loopcount=1000, validfile='/s/neptune/a/tmp/newrna2-valid-4096-1M.hdf5', vocab=['<PAD>', 'A', 'C', 'G', 'T'], weightdecay=0.01)\n"
     ]
    }
   ],
   "source": [
    "from RODAN.basecall import load_model\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "#TODO fix module importing without hacking imports\n",
    "#TODO vocab ATCG - but rna is AUCG\n",
    "torchdict = torch.load('./RODAN/rna.torch', map_location=\"cpu\")\n",
    "origconfig = torchdict[\"config\"]\n",
    "d = origconfig\n",
    "n = SimpleNamespace(**d)\n",
    "args = {\n",
    "    'debug':False, #False\n",
    "    'arch':None,\n",
    "}\n",
    "print(n)\n",
    "# print(type(origconfig))\n",
    "model, device = load_model('./RODAN/rna.torch', config=n, args=SimpleNamespace(**args))\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3573a3f1-0174-4c45-b34b-137bc207cc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([420, 8, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(8,1,4096).to('cuda')).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd6ac50-b750-4495-be59-0a419b879947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3219],\n",
       "        [0.3033],\n",
       "        [0.3036],\n",
       "        [0.3361]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rodan_pretrained import RodanPretrained\n",
    "import torch\n",
    "model = RodanPretrained().cuda()\n",
    "model(torch.rand(4,1,4096).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f6474-785e-4598-b8e5-195ebb3b005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "import torch\n",
    "target = torch.tensor([1, 1, 1,0, 0,0,0])\n",
    "preds = torch.tensor([0, 1,0,1,0, 0,0])\n",
    "confmat = ConfusionMatrix(num_classes=2, normalize='true')\n",
    "confmat(preds, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0944f8-af21-4678-b952-51913c8e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamap import experiment_files\n",
    "len(list(experiment_files['pos_2022_fast'][0].iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdb485-4ab6-463d-a663-bbd5ce1ed571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloading2 import nanopore_datamodule\n",
    "dm = nanopore_datamodule(pos_files = 'pos_2022_fast', neg_files='pos_2022_fast', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1477dc2-ae4a-4df7-81cb-80c83de6a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import RNN\n",
    "import torchmetrics\n",
    "from resnet1d.resnet1d import ResNet1D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f62e90-e1c7-4037-b0c0-29ca6bcaa35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "BertModel(BertConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11fc3e-7a15-464f-9337-fb1567539022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tst import Transformer\n",
    "from transformer.src.benchmark import LSTM, BiGRU, ConvGru, FullyConv, FFN\n",
    "import torch\n",
    "# LSTM(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "# BiGRU(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "# ConvGru(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "# FullyConv(input_dim=1, hidden_dim=64, output_dim=1)\n",
    "# FFN(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "\n",
    "#TODO chunk=none??\n",
    "#TODO attention size\n",
    "leng = 1000\n",
    "model = Transformer(d_input=1, d_model=1, d_output=1,input_length=1000, q=8,v=8,h=8, N=4, attention_size=50, chunk_mode=None, pe='regular', skip_embedding=True)\n",
    "# print(model)\n",
    "print(model(torch.rand(32,1000,1)).size())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533f865-aa90-4e89-a402-3e195ab64df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "\n",
    "        self.net = LSTM(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "        # BiGRU(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "        # ConvGru(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "        # FullyConv(input_dim=1, hidden_dim=64, output_dim=1)\n",
    "        # FFN(input_dim=1, hidden_dim=64, output_dim=1, num_layers=3)\n",
    "\n",
    "        self.acc = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net.forward(x)\n",
    "        return out[:,-1,:]\n",
    "  \n",
    "      \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "      # print(\"LEARNING RATE:\",self.learning_rate)\n",
    "      optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=0.01) #wd 0.01\n",
    "      return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "      x,y = train_batch\n",
    "      output = self(x)\n",
    "      loss = F.binary_cross_entropy_with_logits(output, y)\n",
    "      self.log('train_loss', loss)\n",
    "      acc =self.acc(output, y.int())\n",
    "      self.log('train acc', acc)\n",
    "      return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "      x,y = val_batch\n",
    "      output = self(x)\n",
    "      loss = F.binary_cross_entropy_with_logits(output, y)\n",
    "      self.log('valid_loss', loss)\n",
    "      acc = self.acc(output, y.int())\n",
    "      self.log('valid acc', acc)\n",
    "\n",
    "rnn = GenericModel(0.001)\n",
    "rnn(torch.swapaxes(torch.rand(32,1,1000),-1,-2)).size()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RNAmodEnvRod]",
   "language": "python",
   "name": "conda-env-RNAmodEnvRod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

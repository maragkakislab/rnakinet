# from pathlib import Path
# from rnamodif.workflow.training_configs import training_configs
# from rnamodif.workflow.evaluation_configs import pos_neg_pairs, comparison_groups, decay_exps, prediction_type, pooling, model_name, time_data, exp_groups, hela_decay_exps, model_comparison_groups, MODELS
from config.training_setup import experiments_data, training_configs
from config.evaluation_setup import models_data, exp_groups, pos_neg_pairs, comparison_groups, model_comparison_groups, condition_control_pairs, pooling, datastats_groups
# from config.training_setup import old_exps, nanoid_exps


#Refactor away?
# configfile: "config/config.yml"


include: "rules/basecalling.smk"
include: "rules/alignment.smk"
include: "rules/data_split.smk"
include: "rules/inference.smk"
include: "rules/visualizations.smk"
include: "rules/diff_exp.smk"
include: "rules/training.smk"



# TODO: REPLACE WITH YOUR FILE PATHS
# KEY - name (can be anything)
# VALUE - path to fast5 files, can be nested
# name_to_fast5_path = {
#     '20230706_1704_MN24753_FAR80946_027f7c1e': '/home/jovyan/local_store/arsenite/raw/20230706_mmu_dRNA_3T3_5EU_400_1/runs/no_sample/20230706_1704_MN24753_FAR80946_027f7c1e/fast5_pass',
# }

# for name, path in name_to_fast5_path.items():
#     config['EXPERIMENT_NAME_TO_PATH'][name] = path
#     print('EXISTS', Path(path).exists())

rule all:
    input:
        expand('outputs/visual/predictions/CUSTOM_allneg_maxpool/max_ALL_DONE.txt'),
        
        # expand('outputs/visual/datastats/{group}_sizes_stats.csv', group=['nanoid','nanoid_shock','nia','noars60','3t3','neurons','training'])
        # lambda wildcards: expand('outputs/visual/predictions/{model_name}/{group}_{pooling}_pooling_{plot_type}.pdf',
        #     group=[group for group in comparison_groups.keys()],
        #     model_name = 'CUSTOM_allneg_maxpool', 
        #     pooling=pooling,
        #     plot_type=['auroc', 'thresholds','pr_curve'],
        # ),

        # 'outputs/visual/predictions/CUSTOM_allneg_maxpool/ALL_2022_NIA_max_pooling_chr_f1.pdf',
        # 'outputs/visual/predictions/unlimited_standard_allneg/ALL_2022_NIA_max_pooling_chr_f1.pdf',
        
        # expand('checkpoints_pl/{model}/DONE.txt', model=training_configs.keys()),
        
        # expand('outputs/visual/predictions/NANOID/DMSO_1_REL5_2_{plot_type}.pdf',
              # plot_type=['auroc','pr_curve','thresholds'])
        # expand('outputs/visual/predictions/NANOID/DMSO_1_REL5_2_chrplot_{plot_type}.pdf',
              # plot_type=['auroc']),

        # 'outputs/visual/predictions/CUSTOM_allneg_maxpool/TRAIN_2022_NIA_OLD_max_pooling_chr_f1.pdf',
        # expand('outputs/visual/predictions/CUSTOM_allneg_maxpool/ALL_2022_NIA_max_pooling_chr_{type}.pdf',type=['f1','auroc'])
        # expand('outputs/visual/predictions/CUSTOM_allneg_maxpool/{experiment_name}/self_corr_max_pooling_{reference_level}_decay_plot.pdf',
        #     experiment_name=decay_exps,
        #    reference_level=['gene','transcript'],
        # ),
                



        # expand('outputs/visual/predictions/CUSTOM_allneg_maxpool/max_ALL_DONE.txt'),
        # expand("outputs/splits/{experiment_name}/FAST5_{split}_SPLIT_DONE.txt",
        #       experiment_name=old_exps+nanoid_exps,
        #       split=['train','test','validation'])
        # 'outputs/splits/20180514_1541_K562_5EU_1440_labeled_II_run/FAST5_train_SPLIT_DONE.txt'
        # "outputs/basecalling/20180327_1102_K562_5EU_0_unlabeled_run/guppy/reads.fastq.gz"
        # "outputs/alignment/20180327_1102_K562_5EU_0_unlabeled_run/reads-align.genome.sorted.bam",
        # "outputs/alignment/20180327_1102_K562_5EU_0_unlabeled_run/reads-align.transcriptome.sorted.bam",
        # 'outputs/predictions/CUSTOM_allneg_maxpool/20180226_1208_K562_5EU_60_labeled_run/max_pooling.csv'
        # "outputs/splits/20180514_1541_K562_5EU_1440_labeled_II_run/train_fast5s_list.txt"
        # 'checkpoints_pl/TEST_REFACTOR/DONE.txt',
        # expand('outputs/visual/predictions/CUSTOM_allneg_maxpool/max_ALL_DONE.txt')
        # expand('outputs/visual/predictions/multimodel/{model_group}/{pair_name}_{pooling}_pooling_{plot_type}_multi.pdf',
        #     model_group=['ALL'],
        #     pair_name=['TEST_NANOID','TEST_2022_NIA'],#[pair_name for pair_name in pos_neg_pairs.keys()],
        #     pooling=pooling,
        #     plot_type=['auroc', 'thresholds','pr_curve'],
        # ),


        # "outputs/basecalling/20180327_1102_K562_5EU_0_unlabeled_run/guppy/reads.fastq.gz"
        
        
        # expand('outputs/splits/{experiment_name}/FAST5_{split}_SPLIT_DONE.txt',
               # experiment_name=['20220520_hsa_dRNA_HeLa_5EU_200_1','20220303_hsa_dRNA_HeLa_DMSO_polyA_REL5_2'],
               # split=['train','test','validation']
        # ),

        # 'outputs/visual/predictions/CUSTOM_allneg_maxpool/decay/max_pooling_transcript_read_limit_decay_plot.pdf',
        # 'outputs/visual/joined_predictions/CUSTOM_allneg_maxpool/ALL_NoArs60/max_pooling_transcript_decay_plot.pdf'
        # expand('outputs/visual/datastats/{group}_sizes_stats.csv', group=['nanoid','nanoid_shock','nia','noars60','3t3'])
        # expand('outputs/visual/{prediction_type}/{model_name}/{pooling}_ALL_DONE.txt',
        #     prediction_type=prediction_type, 
        #     model_name = model_name, 
        #     pooling=pooling,
        # ),
        # 'outputs/alignment/ALL_NoArs60/reads-align.transcriptome.sorted.bam'
        # 'outputs/visual/datastats/nia_lengths_dist.pdf',
        # 'outputs/visual/datastats/nanoid_lengths_dist.pdf',
        # expand('outputs/basecalling/{experiment_name}/DONE.txt', experiment_name=individual_exps)
        # expand("outputs/predictions/CUSTOM_allneg_maxpool/{experiment_name}/max_pooling.csv",
        #        experiment_name=name_to_fast5_path.keys(),
        # )
        # expand('outputs/{prediction_type}/{model_name}/{experiment_name}/speedtest/readlimit_{reads_limit}_threads_{threads}.json',
        #       prediction_type=prediction_type,
        #       model_name = model_name,
        #       experiment_name=['20220520_hsa_dRNA_HeLa_DMSO_1'],
        #       reads_limit=[10000, 20000, 30000],
        #       threads=[16, 64],
        # )

# 

